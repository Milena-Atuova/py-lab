## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1


### –ó–∞–¥–∞–Ω–∏–µ 1
```python
name = input("–ò–º—è: ")
age = int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
print(f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age + 1}.")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab1/01_greeting.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
a = float(input("A: ").replace(",", "."))
b = float(input("B: ").replace(",", "."))

print(f"sum={a + b}; avg={(a + b) / 2}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab1/02_sum_avg.png)

### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price=float(input("–¶–µ–Ω–∞: "))
discount=float(input("–°–∫–∏–¥–∫–∞: "))
vat=float(input("–ù–î–°: "))

base=price*(1-discount/100)
vat_amount=base*(vat/100)
total=base+vat_amount
print(f"–ë—Ñ–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f}")
print(f"–ù–î–°: {vat_amount:.2f}")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ: {total:.2f}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab1/03_discount_vat.png)
### –ó–∞–¥–∞–Ω–∏–µ 4
```python
m=int(input("–ú–∏–Ω—É—Ç—ã:"))
print(f"{m//60:02d}:{m%60:02d}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](img/lab1/04_minutes.png)
### –ó–∞–¥–∞–Ω–∏–µ 5
```python
name=input("–§–ò–û:").strip()
n=name.split()
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {n[0][0]}{n[1][0]}{n[2][0]}.")
n2=' '.join(n)
print(f"–î–ª–∏–Ω–∞: {len(n2)}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](img/lab1/05_initials.png)

### –ó–∞–¥–∞–Ω–∏–µ 6
```python
n=int(input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: "))
och=zoch=0
for i in range(n):
    inf=input("–§–∞–º–∏–ª–∏—è, –ò–º—è, –≤–æ–∑—Ä–∞—Å—Ç, —Ñ–æ—Ä–º–∞ –æ–±—É—á–µ–Ω–∏—è: ").split()
    if inf[3]=="True":
        och+=1
    else:
        zoch+=1
print(och,zoch)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](img/lab1/06_people.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2



### –ó–∞–¥–∞–Ω–∏–µ 1.1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0:
        return ValueError

    mn = 10**100
    mx = 10**100

    for i in range(len(nums)):
        if nums[i] < mn:
            mn = nums[i]
        if nums[i] > mx:
            mx = nums[i]

    return tuple([mn, mx])

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab2/01_arrays_min_max.png)
### –ó–∞–¥–∞–Ω–∏–µ 1.2
```python
def unique_sorted(nums: list[float | int]) -> list[float | int]:
    return sorted(set(nums))

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab2/01_arrays_unique_sorted.png)

### –ó–∞–¥–∞–Ω–∏–µ 1.3
```python
def flatten(mat: list[list | tuple]) -> list:
    array = list()
    for arr in mat:
        if not (isinstance(arr, tuple) or isinstance(arr, list)):
            return TypeError
        for member in arr:
            array.append(member)
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab2/01_arrays_flatten.png)




### –ó–∞–¥–∞–Ω–∏–µ 2.1
```python
def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True


def transpose(mat: list[list[float | int]]) -> list[list]:
    if len(mat) == 0:
        return []

    if not check_is_valid(mat=mat):
        return ValueError

    new_matrix = [[0 for j in range(len(mat))] for i in range(len(mat[0]))]

    for i in range(len(mat)):
        for j in range(len(mat[i])):
            new_matrix[j][i] = mat[i][j]

    return new_matrix

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](img/lab2/02_matrix_transpose.png)

### –ó–∞–¥–∞–Ω–∏–µ 2.2
```python

def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True

def row_sums(mat: list[list[float | int]]) -> list[float]:
    if not check_is_valid(mat=mat):
        return ValueError

    array = list()
    for arr in mat:
        array.append(sum(arr))
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](img/lab2/02_matrix_row_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ 2.3
```python

def check_is_valid(mat: list[list[float | int]]) -> bool:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return False
    return True

def col_sums(mat: list[list[float | int]]) -> list[float]:
    if not check_is_valid(mat=mat):
        return ValueError

    array = list(0 for i in range(len(mat[0])))
    for i in range(len(mat)):
        for j in range(len(mat[i])):
            array[j] += mat[i][j]
    return array
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](img/lab2/02_matrix_col_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ 3
```python

def format_record(rec: tuple[str, str, float]) -> str:

    name_data = rec[0].strip().split()

    if len(name_data) > 2:
        surname, name, patronymic = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]} {name[0].upper()}.{patronymic[0].upper()}."
    elif len(name_data) == 2:
        surname, name = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]} {name[0].upper()}."
    elif len(name_data) == 1:
        surname = rec[0].strip().split()
        name_string_data = f"{surname[0].upper()}{surname[1:]}"
    else:
        return ValueError

    group = rec[1].strip()
    if group == "":
        return ValueError

    try:
        gpa = float(rec[2])
    except Exception as _:
        return TypeError

    return f"{name_string_data}, –≥—Ä. {group}, GPA {gpa:.2f}"
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 7](img/lab2/03_tuples.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3



### –ó–∞–¥–∞–Ω–∏–µ A
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace("—ë", "–µ").replace("–Å", "–ï")

    text = text.replace("\t", " ").replace("\r", " ").replace("\n", " ")

    while "  " in text:
        text = text.replace("  ", " ")

    return text.strip()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab3/A.normalize.png)
 ```python
import re

def tokenize(text: str) -> list[str]:
    pattern = r'\b\w+(?:-\w+)*\b'
    return re.findall(pattern, text)

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab3/A.tokenize.png)

```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    counts = {}

    for i in tokens:
        if i in counts:
            counts[i] += 1
        else:
            counts[i] = 1

    return counts



def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    freq = sorted(freq.items(), key=lambda item: [-item[1], item[0]])
    return freq[:n]

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab3/A.top_n.png)


### –ó–∞–¥–∞–Ω–∏–µ B
```python
import sys, os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import normalize, tokenize, count_freq, top_n

text = sys.stdin.readline()

normalized_text = normalize(text)

tokens = tokenize(normalized_text)

total_words = len(tokens)
freq_dict = count_freq(tokens)
unique_words = len(freq_dict)
top_words = top_n(freq_dict, 5)

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
print("–¢–æ–ø-5:")

for word, count in top_words:
    print(f"{word}:{count}")


# –¢–∞–±–ª–∏—Ü–∞
USE_TABLE = True 

if USE_TABLE and top_words:
    # –í—ã—á–∏—Å–ª—è–µ–º —à–∏—Ä–∏–Ω—É –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –ø–æ –¥–ª–∏–Ω–µ —Å–∞–º–æ–≥–æ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞
    max_word_len = max(len(word) for word, i in top_words)
    header_word = "—Å–ª–æ–≤–æ"
    header_freq = "—á–∞—Å—Ç–æ—Ç–∞"

    # –í—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    print(f"{header_word:<{max_word_len}} | {header_freq}")
    print("-" * (max_word_len + 3 + len(header_freq)))

    # –í—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    for word, count in top_words:
        print(f"{word:<{max_word_len}} | {count}")
else:
    for word, count in top_words:
        print(f"{word}:{count}")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab3/B.png)



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4


### –ó–∞–¥–∞–Ω–∏–µ A
```python
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, ROOT_DIR)

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))


from lib.text import normalize, tokenize, count_freq, top_n

from pathlib import Path
import csv
from typing import Iterable, Sequence
from collections import Counter


def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    p = Path(path)
    return p.read_text(encoding=encoding)


def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    rows = list(rows)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)



def frequencies_from_text(text: str) -> dict[str, int]:
    tokens = tokenize(normalize(text))
    return Counter(tokens)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ –≤–∞—à–µ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏


def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))


txt = read_text("data/input.txt")  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
data=[i for i in top_n(count_freq(tokenize(normalize(txt))),n=5)]
write_csv(
    header=("word","count"),
    rows=data,
    path = "data/check.csv" ,
)


```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab4/A_1.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab4/A_2.png)


### –ó–∞–¥–∞–Ω–∏–µ B
```python
aimport sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ lib
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, ROOT_DIR)

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import normalize, tokenize, count_freq, top_n

from lab4.io_txt_csv import read_text, write_csv

PROJECT_ROOT = Path(__file__).parent.parent.parent


input_path = PROJECT_ROOT / "data" / "input.txt"
output_path = PROJECT_ROOT / "data" / "report.csv"
p = read_text(input_path)
norm_p=normalize(p)
tokens=tokenize(norm_p)
count_word=count_freq(tokens)
top=top_n(count_freq(tokenize(normalize(p))))

write_csv(top, output_path, ["word", "count"])

print("–í—Å–µ–≥–æ —Å–ª–æ–≤:", len(tokens))
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:", len(count_word))
print("–¢–æ–ø-5:")
for x,y in top[:5]:
    print(f'{x}:{y}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab4/B.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5


### –ó–∞–¥–∞–Ω–∏–µ A
```python
import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    jp = Path(json_path)
    if jp.suffix != ".json":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    if not jp.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    if len(data) == 0:
        raise ValueError("–ü—É—Å—Ç–æ–π JSON")
    

    all_headers = set()
    for item in data:
        if not isinstance(item, dict):
            raise ValueError("–≠–ª–µ–º–µ–Ω—Ç—ã JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")
        all_headers.update(item.keys())  # –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏ –æ–±—ä–µ–∫—Ç–∞
    
    headers = sorted(all_headers)  # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø–æ—Ä—è–¥–∫–∞
    
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        for item in data:
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, –∑–∞–ø–æ–ª–Ω—è—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
            row = {}
            for header in headers:
                row[header] = item.get(header, '')  # –µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç - –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
            writer.writerow(row)

def csv_to_json(csv_path: str, json_path: str) -> None:
    cp = Path(csv_path)
    if cp.suffix != ".csv":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    if not cp.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    if len(rows) == 0:
        raise ValueError("–ü—É—Å—Ç–æ–π CSV")
    
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(rows, f, ensure_ascii=False, indent=2)


json_to_csv("data/samples/people.json", "data/out/people_from_json.csv")
csv_to_json("data/samples/people.csv", "data/out/people_from_csv.json")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab5/A_1.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab5/A_2.png)


### –ó–∞–¥–∞–Ω–∏–µ B
```python
import csv
from pathlib import Path
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file=Path(csv_path)
    if not csv_file.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    if csv_file.suffix != '.csv':
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")



    wb=Workbook()
    ws=wb.active
    ws.title="Sheet1"

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader= csv.DictReader(f)
        rows = list(reader)
    if len(rows)==0:
        raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")
    if not reader.fieldnames:
        raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")

    ws.append(reader.fieldnames)

    r_count=0
    for row in rows:
        r_count+=1

        data_for_ex=[]
        for title in reader.fieldnames:
            data_for_ex.append(row[title])
        ws.append(data_for_ex)
    if r_count == 0:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")


    for col_index in range(1,len(reader.fieldnames)+1):
        column_letter=get_column_letter(col_index)
        max_len=0


        for row in ws[column_letter]:
            if row.value is not None:
                max_len=max(max_len,len(str(row.value)))

        m_width=max(max_len+2, 8)
        ws.column_dimensions[column_letter].width =m_width


    xlsx_path = Path(xlsx_path)
    wb.save(xlsx_path)


csv_to_xlsx("data/samples/people.csv", "data/out/people.xlsx")
csv_to_xlsx("data/samples/cities.csv", "data/out/cities.xlsx")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab5/B.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6


### –ó–∞–¥–∞–Ω–∏–µ A
```python
import argparse
from pathlib import Path
from src.lib.text import tokenize, count_freq, top_n

def main():
    
    # —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ø–∞—Ä—Å–µ—Ä–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—ã
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")

   
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–º–∞–Ω–¥—ã")

    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument("--top", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤ "
    "(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)")
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    args = parser.parse_args()

    file = Path(args.input) # —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ Path –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É

    if not file.exists():
        parser.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if args.command == "cat": # —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã cat
        with open(file, "r", encoding="utf-8") as f:
            number = 1
            for row in f:
                row = row.rstrip("\n") 
                if args.n: # –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–ª–∞–≥ n -> –ø–µ—á–∞—Ç–∞–µ–º –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∏
                    print(f"{number}: {row}")
                    number += 1
                else:
                    print(row)

    elif args.command == "stats": # —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã stats
        with open(file, "r", encoding="utf-8") as f:
            data = [row for row in f]
        data = "".join(data)
        tokens = tokenize(text=data)
        freq = count_freq(tokens=tokens)
        top = top_n(freq=freq, n=args.top)

        # –≤—ã–≤–æ–¥–∏–º —Ç–æ–ø —Å–ª–æ–≤
        number = 1
        for x, y in top:
            print(f"{number}. {x} - {y}")
            number += 1

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab6/A_1.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab6/A_2.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab6/A_3.png)


### –ó–∞–¥–∞–Ω–∏–µ B
```python
import argparse
from pathlib import Path
from src.lab5.json_csv import json_to_csv, csv_to_json
from src.lab5.csv_xlsx import csv_to_xlsx  

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏")
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")

    # JSON ‚Üí CSV
    json_to_csv_parser = subparsers.add_parser("json_to_csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json_to_csv_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    json_to_csv_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")

    # CSV ‚Üí JSON
    csv_to_json_parser = subparsers.add_parser("csv_to_json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv_to_json_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_json_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")

    # CSV ‚Üí XLSX
    csv_to_xlsx_parser = subparsers.add_parser("csv_to_xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX")
    csv_to_xlsx_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_xlsx_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX —Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.command == "json_to_csv":
        json_to_csv(json_path=args.input, csv_path=args.output)

    elif args.command == "csv_to_json":
        csv_to_json(csv_path=args.input, json_path=args.output)

    elif args.command == "csv_to_xlsx":
        csv_to_xlsx(csv_path=args.input, xlsx_path=args.output)

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](img/lab6/B_1.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](img/lab6/B_2.png)


![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](img/lab6/B_3.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7


### –ó–∞–¥–∞–Ω–∏–µ A
```python

import pytest

from src.lib.text import count_freq, normalize, tokenize, top_n


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize(src, expected):
    assert normalize(src) == expected


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize(src, expected):
    assert tokenize(src) == expected


def test_count_and_top():
    tokens = ["a", "b", "a", "c", "b", "a"]
    freq = count_freq(tokens)
    assert freq == {"a": 3, "b": 2, "c": 1}
    assert top_n(freq, 2) == [("a", 3), ("b", 2)]


def test_top_tie_breaker():
    freq = count_freq(["bb", "aa", "bb", "aa", "cc"])
    assert top_n(freq, 2) == [("aa", 2), ("bb", 2)]


def test_dop():
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—É—Å—Ç—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    assert normalize("") == ""
    assert tokenize("") == []
    assert count_freq([]) == {}
    assert top_n({}, 5) == []


def test_top_dop():
    """–ó–∞–ø—Ä–æ—Å –±–æ–ª—å—à–µ–≥–æ N —á–µ–º –µ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    freq = {"a": 3, "b": 2}
    assert top_n(freq, 5) == [("a", 3), ("b", 2)]

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab7/A.png)




### –ó–∞–¥–∞–Ω–∏–µ B
```python
import json, csv
from pathlib import Path
import pytest
from src.lab5.json_csv import json_to_csv, csv_to_json


def write_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def read_csv_rows(path: Path):
    with path.open(encoding="utf-8") as f:
        return list(csv.DictReader(f))


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}]
    write_json(src, data)

    json_to_csv(str(src), str(dst))
    rows = read_csv_rows(dst)
    assert len(rows) == 2
    assert set(rows[0]) >= {"name", "age"}


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    src.write_text("name,age\nAlice,22\nBob,25\n", encoding="utf-8")

    csv_to_json(str(src), str(dst))
    obj = json.loads(dst.read_text(encoding="utf-8"))
    assert isinstance(obj, list) and len(obj) == 2
    assert set(obj[0]) == {"name", "age"}


def test_json_to_csv_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ JSON - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.json"
    dst = tmp_path / "empty.csv"
    src.write_text("[]", encoding="utf-8")

    try:
        json_to_csv(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, IndexError):
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –±—Ä–æ—Å–∏–ª–∞ –æ–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ - —ç—Ç–æ —Ç–æ–∂–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        pass


def test_csv_to_json_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ CSV - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.csv"
    dst = tmp_path / "empty.json"
    src.write_text("", encoding="utf-8")

    try:
        csv_to_json(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, Exception):
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –±—Ä–æ—Å–∏–ª–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ - —ç—Ç–æ —Ç–æ–∂–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        pass


def test_missing_file(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        csv_to_json("nope.csv", str(tmp_path / "out.json"))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if (tmp_path / "out.json").exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except FileNotFoundError:
        # –ï—Å–ª–∏ –±—Ä–æ—Å–∏–ª–æ FileNotFoundError - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
        pass

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab7/B.png)


### –ó–∞–¥–∞–Ω–∏–µ C
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](img/lab7/C.png)






## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8


### models.py
```python

from datetime import datetime, date
from dataclasses import dataclass
@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):
        #  –í–∞–ª–∏–¥–∞—Ü–∏—è birthdate
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. –û–∂–∏–¥–∞–µ—Ç—Å—è YYYY-MM-DD")

        #  –í–∞–ª–∏–¥–∞—Ü–∏—è GPA
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0..5, –ø–æ–ª—É—á–µ–Ω–æ: {self.gpa}")

    # –í–æ–∑—Ä–∞—Å—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞
    def age(self) -> int:
        birth = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        years = today.year - birth.year
        if (today.month, today.day) < (birth.month, birth.day):
            years -= 1
        return years
    # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }


    # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è

    @classmethod
    def from_dict(cls, d: dict):
        return cls(
            fio=d["fio"],
            birthdate=d["birthdate"],
            group=d["group"],
            gpa=d["gpa"]
        )

    def __str__(self):
        return f"{self.fio} ({self.group}), –≤–æ–∑—Ä–∞—Å—Ç: {self.age()}, GPA: {self.gpa}"

```


### serialize.py
```python
import json
from .models import Student
def students_to_json(students, path):
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª."
    data = [s.to_dict() for s in students]

    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def students_from_json(path) -> list[Student]:
    "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞."
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)

    result = []
    for d in raw:
        result.append(Student.from_dict(d))

    return result

```

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](img/lab8/A.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](img/lab8/B.png)

